"""
BytePlus Seedream Node for ComfyUI
ä½¿ç”¨BytePlus ModelArk Seedream 4.5/4.0æ¨¡åž‹è¿›è¡Œæ–‡ç”Ÿå›¾
å‚è€ƒæ–‡æ¡£: https://docs.byteplus.com/en/docs/ModelArk/1824121

ä½¿ç”¨BytePluså®˜æ–¹Ark SDKè°ƒç”¨API
å®‰è£…SDK: pip install byteplus-python-sdk-v2
"""

import os
import time
import base64
import requests
import numpy as np
from PIL import Image
from io import BytesIO
from typing import Optional, List, Union

import folder_paths
import torch

# ä½¿ç”¨BytePluså®˜æ–¹Ark SDK
from byteplussdkarkruntime import Ark
from byteplussdkarkruntime.types.images.images import SequentialImageGenerationOptions

# APIé…ç½®
BYTEPLUS_API_BASE_URL = "https://ark.ap-southeast.bytepluses.com/api/v3"


class SeedreamTextToImage:
    """
    BytePlus Seedream 4.5/4.0 æ–‡ç”Ÿå›¾èŠ‚ç‚¹
    ä½¿ç”¨BytePluså®˜æ–¹Ark SDKè°ƒç”¨Seedreamæ¨¡åž‹ç”Ÿæˆå›¾ç‰‡
    """
    
    # æ”¯æŒçš„æ¨¡åž‹
    MODELS = [
        "seedream-4-5-251128",  # Seedream 4.5 (æŽ¨è)
        "seedream-4-0-250828",  # Seedream 4.0
    ]
    
    # æ”¯æŒçš„å›¾ç‰‡å°ºå¯¸
    SIZES = [
        "512x512",
        "768x768", 
        "1024x1024",
        "1280x720",
        "720x1280",
        "1920x1080",
        "1080x1920",
        "2560x1440",
        "1440x2560",
        "2K",  # 2Kåˆ†è¾¨çŽ‡
    ]
    
    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()
        
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "A beautiful sunset over the ocean with vibrant orange and purple colors, photorealistic style",
                    "tooltip": "å›¾ç‰‡æè¿°æ–‡æœ¬ (è‹±æ–‡æ•ˆæžœæ›´ä½³)"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": "",
                    "tooltip": "BytePlus APIå¯†é’¥ (ä¹Ÿå¯é€šè¿‡çŽ¯å¢ƒå˜é‡ARK_API_KEYè®¾ç½®)"
                }),
                "model": (cls.MODELS, {
                    "default": "seedream-4-5-251128",
                    "tooltip": "é€‰æ‹©Seedreamæ¨¡åž‹ç‰ˆæœ¬"
                }),
                "size": (cls.SIZES, {
                    "default": "1024x1024",
                    "tooltip": "ç”Ÿæˆå›¾ç‰‡çš„å°ºå¯¸"
                }),
            },
            "optional": {
                "api_base_url": ("STRING", {
                    "multiline": False,
                    "default": BYTEPLUS_API_BASE_URL,
                    "tooltip": "APIåŸºç¡€URL"
                }),
                "watermark": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"
                }),
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 0x7FFFFFFF,
                    "tooltip": "éšæœºç§å­ (-1ä¸ºéšæœº)"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("image", "image_url", "status_message")
    FUNCTION = "generate_image"
    CATEGORY = "image/generation"
    OUTPUT_NODE = True
    
    def generate_image(self, prompt: str, api_key: str, model: str, size: str,
                       api_base_url: str = BYTEPLUS_API_BASE_URL,
                       watermark: bool = False, seed: int = -1):
        """
        è°ƒç”¨Seedream APIç”Ÿæˆå›¾ç‰‡ (ä½¿ç”¨BytePlus Ark SDK)
        """
        try:
            # èŽ·å–APIå¯†é’¥
            effective_api_key = api_key if api_key else os.environ.get("ARK_API_KEY", "")
            if not effective_api_key:
                error_msg = "âŒ é”™è¯¯ï¼šæœªæä¾›APIå¯†é’¥ã€‚è¯·åœ¨èŠ‚ç‚¹ä¸­è¾“å…¥æˆ–è®¾ç½®çŽ¯å¢ƒå˜é‡ARK_API_KEY"
                empty_image = self._create_empty_image()
                return (empty_image, "", error_msg)
            
            # åˆ›å»ºArkå®¢æˆ·ç«¯
            client = Ark(
                base_url=api_base_url,
                api_key=effective_api_key,
            )
            
            print(f"ðŸŽ¨ æ­£åœ¨è°ƒç”¨Seedream APIç”Ÿæˆå›¾ç‰‡...")
            print(f"   æ¨¡åž‹: {model}")
            print(f"   å°ºå¯¸: {size}")
            print(f"   æç¤ºè¯: {prompt[:100]}...")
            
            start_time = time.time()
            
            # æž„å»ºå‚æ•°
            generate_params = {
                "model": model,
                "prompt": prompt,
                "size": size,
                "response_format": "url",
                "watermark": watermark,
            }
            
            # æ·»åŠ ç§å­
            if seed >= 0:
                generate_params["seed"] = seed
            
            # è°ƒç”¨APIç”Ÿæˆå›¾ç‰‡ (ä½¿ç”¨Ark SDK)
            images_response = client.images.generate(**generate_params)
            
            elapsed_time = time.time() - start_time
            
            # èŽ·å–å›¾ç‰‡URL
            if images_response.data and len(images_response.data) > 0:
                image_url = images_response.data[0].url
                
                if image_url:
                    # ä¸‹è½½å›¾ç‰‡
                    image_tensor = self._download_and_convert_image(image_url)
                    
                    status_message = (
                        f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼\n"
                        f"   æ¨¡åž‹: {model}\n"
                        f"   å°ºå¯¸: {size}\n"
                        f"   è€—æ—¶: {elapsed_time:.2f}ç§’"
                    )
                    print(status_message)
                    
                    return (image_tensor, image_url, status_message)
            
            error_msg = f"âŒ æ— æ³•èŽ·å–å›¾ç‰‡URL"
            print(error_msg)
            empty_image = self._create_empty_image()
            return (empty_image, "", error_msg)
            
        except Exception as e:
            error_msg = f"âŒ ç”Ÿæˆå›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            empty_image = self._create_empty_image()
            return (empty_image, "", error_msg)
    
    def _download_and_convert_image(self, url: str) -> torch.Tensor:
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼"""
        print(f"ðŸ“¥ æ­£åœ¨ä¸‹è½½å›¾ç‰‡: {url[:80]}...")
        response = requests.get(url, timeout=60)
        response.raise_for_status()
        
        image = Image.open(BytesIO(response.content))
        image = image.convert("RGB")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œç„¶åŽè½¬æ¢ä¸ºtorchå¼ é‡
        image_np = np.array(image).astype(np.float32) / 255.0
        image_tensor = torch.from_numpy(image_np)[None,]
        
        return image_tensor
    
    def _create_empty_image(self, width: int = 512, height: int = 512) -> torch.Tensor:
        """åˆ›å»ºç©ºç™½å›¾ç‰‡ï¼ˆç”¨äºŽé”™è¯¯æƒ…å†µï¼‰"""
        empty = np.zeros((height, width, 3), dtype=np.float32)
        return torch.from_numpy(empty)[None,]


class SeedreamImageToImage:
    """
    BytePlus Seedream å›¾ç”Ÿå›¾èŠ‚ç‚¹
    ä½¿ç”¨è¾“å…¥å›¾ç‰‡å’Œæ–‡æœ¬æç¤ºç”Ÿæˆæ–°å›¾ç‰‡
    """
    
    MODELS = SeedreamTextToImage.MODELS
    SIZES = SeedreamTextToImage.SIZES
    
    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()
        
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {
                    "tooltip": "è¾“å…¥å‚è€ƒå›¾ç‰‡"
                }),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "Keep the subject and composition, change the style to oil painting",
                    "tooltip": "ç¼–è¾‘æŒ‡ä»¤ (æè¿°å¦‚ä½•ä¿®æ”¹å›¾ç‰‡)"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": "",
                    "tooltip": "BytePlus APIå¯†é’¥"
                }),
                "model": (cls.MODELS, {
                    "default": "seedream-4-5-251128",
                    "tooltip": "é€‰æ‹©Seedreamæ¨¡åž‹ç‰ˆæœ¬"
                }),
                "size": (cls.SIZES, {
                    "default": "1024x1024",
                    "tooltip": "ç”Ÿæˆå›¾ç‰‡çš„å°ºå¯¸"
                }),
            },
            "optional": {
                "api_base_url": ("STRING", {
                    "multiline": False,
                    "default": BYTEPLUS_API_BASE_URL,
                    "tooltip": "APIåŸºç¡€URL"
                }),
                "watermark": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("image", "image_url", "status_message")
    FUNCTION = "generate_image"
    CATEGORY = "image/generation"
    OUTPUT_NODE = True
    
    def generate_image(self, image: torch.Tensor, prompt: str, api_key: str, 
                       model: str, size: str,
                       api_base_url: str = BYTEPLUS_API_BASE_URL,
                       watermark: bool = False):
        """
        è°ƒç”¨Seedream APIè¿›è¡Œå›¾ç”Ÿå›¾ (ä½¿ç”¨BytePlus Ark SDK)
        """
        try:
            # èŽ·å–APIå¯†é’¥
            effective_api_key = api_key if api_key else os.environ.get("ARK_API_KEY", "")
            if not effective_api_key:
                error_msg = "âŒ é”™è¯¯ï¼šæœªæä¾›APIå¯†é’¥"
                empty_image = self._create_empty_image()
                return (empty_image, "", error_msg)
            
            # å°†è¾“å…¥å›¾ç‰‡è½¬æ¢ä¸ºbase64 data URL
            image_data_url = self._tensor_to_data_url(image)
            
            # åˆ›å»ºArkå®¢æˆ·ç«¯
            client = Ark(
                base_url=api_base_url,
                api_key=effective_api_key,
            )
            
            print(f"ðŸŽ¨ æ­£åœ¨è°ƒç”¨Seedream APIè¿›è¡Œå›¾ç”Ÿå›¾...")
            print(f"   æ¨¡åž‹: {model}")
            print(f"   å°ºå¯¸: {size}")
            print(f"   æç¤ºè¯: {prompt[:100]}...")
            
            start_time = time.time()
            
            # è°ƒç”¨API (ä½¿ç”¨Ark SDK)
            images_response = client.images.generate(
                model=model,
                prompt=prompt,
                image=image_data_url,
                size=size,
                response_format="url",
                watermark=watermark,
            )
            
            elapsed_time = time.time() - start_time
            
            # èŽ·å–å›¾ç‰‡URL
            if images_response.data and len(images_response.data) > 0:
                image_url = images_response.data[0].url
                
                if image_url:
                    image_tensor = self._download_and_convert_image(image_url)
                    
                    status_message = (
                        f"âœ… å›¾ç”Ÿå›¾æˆåŠŸï¼\n"
                        f"   æ¨¡åž‹: {model}\n"
                        f"   è€—æ—¶: {elapsed_time:.2f}ç§’"
                    )
                    print(status_message)
                    
                    return (image_tensor, image_url, status_message)
            
            error_msg = f"âŒ æ— æ³•èŽ·å–å›¾ç‰‡URL"
            print(error_msg)
            empty_image = self._create_empty_image()
            return (empty_image, "", error_msg)
            
        except Exception as e:
            error_msg = f"âŒ å›¾ç”Ÿå›¾æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            empty_image = self._create_empty_image()
            return (empty_image, "", error_msg)
    
    def _tensor_to_data_url(self, image_tensor: torch.Tensor) -> str:
        """å°†ComfyUIå›¾ç‰‡å¼ é‡è½¬æ¢ä¸ºdata URL"""
        # å–ç¬¬ä¸€å¼ å›¾ç‰‡
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor[0]
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        image_np = (image_tensor.cpu().numpy() * 255).astype(np.uint8)
        
        # è½¬æ¢ä¸ºPIL Image
        image = Image.fromarray(image_np)
        
        # ä¿å­˜ä¸ºbase64
        buffer = BytesIO()
        image.save(buffer, format="PNG")
        b64_data = base64.b64encode(buffer.getvalue()).decode()
        
        return f"data:image/png;base64,{b64_data}"
    
    def _download_and_convert_image(self, url: str) -> torch.Tensor:
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼"""
        response = requests.get(url, timeout=60)
        response.raise_for_status()
        
        image = Image.open(BytesIO(response.content))
        image = image.convert("RGB")
        
        image_np = np.array(image).astype(np.float32) / 255.0
        image_tensor = torch.from_numpy(image_np)[None,]
        
        return image_tensor
    
    def _create_empty_image(self, width: int = 512, height: int = 512) -> torch.Tensor:
        """åˆ›å»ºç©ºç™½å›¾ç‰‡"""
        empty = np.zeros((height, width, 3), dtype=np.float32)
        return torch.from_numpy(empty)[None,]


class SeedreamTextToBatchImage:
    """
    BytePlus Seedream æ–‡å­—æ‰¹é‡ç”Ÿæˆå›¾ç‰‡èŠ‚ç‚¹
    Text-to-Batch-Imageï¼ˆText Input, Batch Image Output)
    å‚è€ƒ: https://docs.byteplus.com/en/docs/ModelArk/1824121#batch-image-output
    """
    
    MODELS = SeedreamTextToImage.MODELS
    SIZES = SeedreamTextToImage.SIZES
    
    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()
        
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "Generate a series of 4 coherent illustrations focusing on the same corner of a courtyard across the four seasons, presented in a unified style that captures the unique colors, elements, and atmosphere of each season.",
                    "tooltip": "æ‰¹é‡ç”Ÿæˆæç¤ºè¯ (æè¿°è¦ç”Ÿæˆçš„ç³»åˆ—å›¾ç‰‡)"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": "",
                    "tooltip": "BytePlus APIå¯†é’¥"
                }),
                "model": (cls.MODELS, {
                    "default": "seedream-4-5-251128",
                    "tooltip": "é€‰æ‹©Seedreamæ¨¡åž‹ç‰ˆæœ¬"
                }),
                "size": (cls.SIZES, {
                    "default": "2K",
                    "tooltip": "ç”Ÿæˆå›¾ç‰‡çš„å°ºå¯¸"
                }),
                "max_images": ("INT", {
                    "default": 4,
                    "min": 2,
                    "max": 8,
                    "step": 1,
                    "tooltip": "æœ€å¤§ç”Ÿæˆå›¾ç‰‡æ•°é‡"
                }),
            },
            "optional": {
                "api_base_url": ("STRING", {
                    "multiline": False,
                    "default": BYTEPLUS_API_BASE_URL,
                    "tooltip": "APIåŸºç¡€URL"
                }),
                "watermark": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "status_message")
    FUNCTION = "generate_batch"
    CATEGORY = "image/generation"
    OUTPUT_NODE = True
    
    def generate_batch(self, prompt: str, api_key: str, model: str, size: str,
                       max_images: int = 4,
                       api_base_url: str = BYTEPLUS_API_BASE_URL,
                       watermark: bool = False):
        """
        è°ƒç”¨Seedream APIæ‰¹é‡ç”Ÿæˆå›¾ç‰‡ (ä½¿ç”¨BytePlus Ark SDK)
        Text-to-Batch-Image
        """
        try:
            # èŽ·å–APIå¯†é’¥
            effective_api_key = api_key if api_key else os.environ.get("ARK_API_KEY", "")
            if not effective_api_key:
                error_msg = "âŒ é”™è¯¯ï¼šæœªæä¾›APIå¯†é’¥"
                empty_image = self._create_empty_image()
                return (empty_image, error_msg)
            
            # åˆ›å»ºArkå®¢æˆ·ç«¯
            client = Ark(
                base_url=api_base_url,
                api_key=effective_api_key,
            )

            prompt = f"Generate {max_images} images based on the prompt: {prompt}"
            
            print(f"ðŸŽ¨ æ­£åœ¨è°ƒç”¨Seedream APIæ‰¹é‡ç”Ÿæˆå›¾ç‰‡ (Text-to-Batch-Image)...")
            print(f"   æ¨¡åž‹: {model}")
            print(f"   å°ºå¯¸: {size}")
            print(f"   æœ€å¤§å›¾ç‰‡æ•°: {max_images}")
            print(f"   æç¤ºè¯: {prompt}...")
            
            start_time = time.time()
            
            # è°ƒç”¨API - æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼
            images_response = client.images.generate(
                model=model,
                prompt=prompt,
                size=size,
                sequential_image_generation="auto",
                sequential_image_generation_options=SequentialImageGenerationOptions(max_images=max_images),
                response_format="url",
                watermark=watermark,
            )
            
            elapsed_time = time.time() - start_time
            
            # ä¸‹è½½æ‰€æœ‰å›¾ç‰‡
            if images_response.data and len(images_response.data) > 0:
                print(images_response.data)
                images = []
                for idx, image_data in enumerate(images_response.data):
                    image_url = image_data.url
                    image_size = getattr(image_data, 'size', 'unknown')
                    if image_url:
                        print(f"ðŸ“¥ ä¸‹è½½å›¾ç‰‡ {idx + 1}/{len(images_response.data)} (URL: {image_url[:60]}..., Size: {image_size})")
                        image_tensor = self._download_and_convert_image(image_url)
                        images.append(image_tensor)
                
                if images:
                    # åˆå¹¶æ‰€æœ‰å›¾ç‰‡ä¸ºbatch
                    batch_tensor = torch.cat(images, dim=0)
                    
                    status_message = (
                        f"âœ… æ‰¹é‡ç”ŸæˆæˆåŠŸï¼\n"
                        f"   ç”Ÿæˆå›¾ç‰‡æ•°: {len(images)}\n"
                        f"   æ¨¡åž‹: {model}\n"
                        f"   è€—æ—¶: {elapsed_time:.2f}ç§’"
                    )
                    print(status_message)
                    
                    return (batch_tensor, status_message)
            
            error_msg = f"âŒ æ— æ³•èŽ·å–å›¾ç‰‡"
            print(error_msg)
            empty_image = self._create_empty_image()
            return (empty_image, error_msg)
            
        except Exception as e:
            error_msg = f"âŒ æ‰¹é‡ç”Ÿæˆæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            empty_image = self._create_empty_image()
            return (empty_image, error_msg)
    
    def _download_and_convert_image(self, url: str) -> torch.Tensor:
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼"""
        response = requests.get(url, timeout=60)
        response.raise_for_status()
        
        image = Image.open(BytesIO(response.content))
        image = image.convert("RGB")
        
        image_np = np.array(image).astype(np.float32) / 255.0
        image_tensor = torch.from_numpy(image_np)[None,]
        
        return image_tensor
    
    def _create_empty_image(self, width: int = 512, height: int = 512) -> torch.Tensor:
        """åˆ›å»ºç©ºç™½å›¾ç‰‡"""
        empty = np.zeros((height, width, 3), dtype=np.float32)
        return torch.from_numpy(empty)[None,]


class SeedreamImageToBatchImage:
    """
    BytePlus Seedream å›¾ç”Ÿæ‰¹é‡å›¾ç‰‡èŠ‚ç‚¹
    Image-to-Batch-Image (Single Image Input, Batch Image Output)
    å‚è€ƒ: https://docs.byteplus.com/en/docs/ModelArk/1824121#batch-image-output
    """
    
    MODELS = SeedreamTextToImage.MODELS
    SIZES = SeedreamTextToImage.SIZES
    
    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()
        
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {
                    "tooltip": "è¾“å…¥å‚è€ƒå›¾ç‰‡"
                }),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "Using this LOGO as a reference, create a visual design system for an outdoor sports brand named GREEN, including packaging bags, hats, cards, lanyards, etc. Main visual tone is green, with a fun, simple, and modern style.",
                    "tooltip": "æ‰¹é‡ç”Ÿæˆæç¤ºè¯"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": "",
                    "tooltip": "BytePlus APIå¯†é’¥"
                }),
                "model": (cls.MODELS, {
                    "default": "seedream-4-5-251128",
                    "tooltip": "é€‰æ‹©Seedreamæ¨¡åž‹ç‰ˆæœ¬"
                }),
                "size": (cls.SIZES, {
                    "default": "2K",
                    "tooltip": "ç”Ÿæˆå›¾ç‰‡çš„å°ºå¯¸"
                }),
                "max_images": ("INT", {
                    "default": 4,
                    "min": 2,
                    "max": 8,
                    "step": 1,
                    "tooltip": "æœ€å¤§ç”Ÿæˆå›¾ç‰‡æ•°é‡"
                }),
            },
            "optional": {
                "api_base_url": ("STRING", {
                    "multiline": False,
                    "default": BYTEPLUS_API_BASE_URL,
                    "tooltip": "APIåŸºç¡€URL"
                }),
                "watermark": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "status_message")
    FUNCTION = "generate_batch"
    CATEGORY = "image/generation"
    OUTPUT_NODE = True
    
    def generate_batch(self, image: torch.Tensor, prompt: str, api_key: str, 
                       model: str, size: str, max_images: int = 4,
                       api_base_url: str = BYTEPLUS_API_BASE_URL,
                       watermark: bool = False):
        """
        è°ƒç”¨Seedream APIè¿›è¡Œå›¾ç”Ÿæ‰¹é‡å›¾ç‰‡ (ä½¿ç”¨BytePlus Ark SDK)
        Image-to-Batch-Image
        """
        try:
            # èŽ·å–APIå¯†é’¥
            effective_api_key = api_key if api_key else os.environ.get("ARK_API_KEY", "")
            if not effective_api_key:
                error_msg = "âŒ é”™è¯¯ï¼šæœªæä¾›APIå¯†é’¥"
                empty_image = self._create_empty_image()
                return (empty_image, error_msg)
            
            # å°†è¾“å…¥å›¾ç‰‡è½¬æ¢ä¸ºdata URL
            image_data_url = self._tensor_to_data_url(image)
            
            # åˆ›å»ºArkå®¢æˆ·ç«¯
            client = Ark(
                base_url=api_base_url,
                api_key=effective_api_key,
            )
            
            print(f"ðŸŽ¨ æ­£åœ¨è°ƒç”¨Seedream APIæ‰¹é‡ç”Ÿæˆå›¾ç‰‡ (Image-to-Batch-Image)...")
            print(f"   æ¨¡åž‹: {model}")
            print(f"   å°ºå¯¸: {size}")
            print(f"   æœ€å¤§å›¾ç‰‡æ•°: {max_images}")
            print(f"   æç¤ºè¯: {prompt[:100]}...")
            
            start_time = time.time()
            
            # è°ƒç”¨API - æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼
            images_response = client.images.generate(
                model=model,
                prompt=prompt,
                image=image_data_url,
                size=size,
                sequential_image_generation="auto",
                sequential_image_generation_options=SequentialImageGenerationOptions(max_images=max_images),
                response_format="url",
                watermark=watermark,
            )
            
            elapsed_time = time.time() - start_time
            
            # ä¸‹è½½æ‰€æœ‰å›¾ç‰‡
            if images_response.data and len(images_response.data) > 0:
                images = []
                for idx, image_data in enumerate(images_response.data):
                    image_url = image_data.url
                    image_size = getattr(image_data, 'size', 'unknown')
                    if image_url:
                        print(f"ðŸ“¥ ä¸‹è½½å›¾ç‰‡ {idx + 1}/{len(images_response.data)} (Size: {image_size})")
                        image_tensor = self._download_and_convert_image(image_url)
                        images.append(image_tensor)
                
                if images:
                    # åˆå¹¶æ‰€æœ‰å›¾ç‰‡ä¸ºbatch
                    batch_tensor = torch.cat(images, dim=0)
                    
                    status_message = (
                        f"âœ… å›¾ç”Ÿæ‰¹é‡å›¾ç‰‡æˆåŠŸï¼\n"
                        f"   ç”Ÿæˆå›¾ç‰‡æ•°: {len(images)}\n"
                        f"   æ¨¡åž‹: {model}\n"
                        f"   è€—æ—¶: {elapsed_time:.2f}ç§’"
                    )
                    print(status_message)
                    
                    return (batch_tensor, status_message)
            
            error_msg = f"âŒ æ— æ³•èŽ·å–å›¾ç‰‡"
            print(error_msg)
            empty_image = self._create_empty_image()
            return (empty_image, error_msg)
            
        except Exception as e:
            error_msg = f"âŒ å›¾ç”Ÿæ‰¹é‡å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            empty_image = self._create_empty_image()
            return (empty_image, error_msg)
    
    def _tensor_to_data_url(self, image_tensor: torch.Tensor) -> str:
        """å°†ComfyUIå›¾ç‰‡å¼ é‡è½¬æ¢ä¸ºdata URL"""
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor[0]
        
        image_np = (image_tensor.cpu().numpy() * 255).astype(np.uint8)
        image = Image.fromarray(image_np)
        
        buffer = BytesIO()
        image.save(buffer, format="PNG")
        b64_data = base64.b64encode(buffer.getvalue()).decode()
        
        return f"data:image/png;base64,{b64_data}"
    
    def _download_and_convert_image(self, url: str) -> torch.Tensor:
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼"""
        response = requests.get(url, timeout=60)
        response.raise_for_status()
        
        image = Image.open(BytesIO(response.content))
        image = image.convert("RGB")
        
        image_np = np.array(image).astype(np.float32) / 255.0
        image_tensor = torch.from_numpy(image_np)[None,]
        
        return image_tensor
    
    def _create_empty_image(self, width: int = 512, height: int = 512) -> torch.Tensor:
        """åˆ›å»ºç©ºç™½å›¾ç‰‡"""
        empty = np.zeros((height, width, 3), dtype=np.float32)
        return torch.from_numpy(empty)[None,]


class SeedreamMultiImageToBatchImage:
    """
    BytePlus Seedream å¤šå›¾ç”Ÿæ‰¹é‡å›¾ç‰‡èŠ‚ç‚¹
    Multi-Image-to-Batch-Image (Multi-Image Input, Batch-Image Output)
    å‚è€ƒ: https://docs.byteplus.com/en/docs/ModelArk/1824121#batch-image-output
    """
    
    MODELS = SeedreamTextToImage.MODELS
    SIZES = SeedreamTextToImage.SIZES
    
    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()
        
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image1": ("IMAGE", {
                    "tooltip": "ç¬¬ä¸€å¼ å‚è€ƒå›¾ç‰‡"
                }),
                "image2": ("IMAGE", {
                    "tooltip": "ç¬¬äºŒå¼ å‚è€ƒå›¾ç‰‡"
                }),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "Generate 3 images of a girl and a cow plushie happily riding a roller coaster in an amusement park, depicting morning, noon, and night.",
                    "tooltip": "æ‰¹é‡ç”Ÿæˆæç¤ºè¯"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": "",
                    "tooltip": "BytePlus APIå¯†é’¥"
                }),
                "model": (cls.MODELS, {
                    "default": "seedream-4-5-251128",
                    "tooltip": "é€‰æ‹©Seedreamæ¨¡åž‹ç‰ˆæœ¬"
                }),
                "size": (cls.SIZES, {
                    "default": "2K",
                    "tooltip": "ç”Ÿæˆå›¾ç‰‡çš„å°ºå¯¸"
                }),
                "max_images": ("INT", {
                    "default": 3,
                    "min": 2,
                    "max": 8,
                    "step": 1,
                    "tooltip": "æœ€å¤§ç”Ÿæˆå›¾ç‰‡æ•°é‡"
                }),
            },
            "optional": {
                "image3": ("IMAGE", {
                    "tooltip": "ç¬¬ä¸‰å¼ å‚è€ƒå›¾ç‰‡ (å¯é€‰)"
                }),
                "api_base_url": ("STRING", {
                    "multiline": False,
                    "default": BYTEPLUS_API_BASE_URL,
                    "tooltip": "APIåŸºç¡€URL"
                }),
                "watermark": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "status_message")
    FUNCTION = "generate_batch"
    CATEGORY = "image/generation"
    OUTPUT_NODE = True
    
    def generate_batch(self, image1: torch.Tensor, image2: torch.Tensor, 
                       prompt: str, api_key: str, model: str, size: str,
                       max_images: int = 3,
                       image3: Optional[torch.Tensor] = None,
                       api_base_url: str = BYTEPLUS_API_BASE_URL,
                       watermark: bool = False):
        """
        è°ƒç”¨Seedream APIè¿›è¡Œå¤šå›¾ç”Ÿæ‰¹é‡å›¾ç‰‡ (ä½¿ç”¨BytePlus Ark SDK)
        Multi-Image-to-Batch-Image
        """
        try:
            # èŽ·å–APIå¯†é’¥
            effective_api_key = api_key if api_key else os.environ.get("ARK_API_KEY", "")
            if not effective_api_key:
                error_msg = "âŒ é”™è¯¯ï¼šæœªæä¾›APIå¯†é’¥"
                empty_image = self._create_empty_image()
                return (empty_image, error_msg)
            
            # å°†å›¾ç‰‡è½¬æ¢ä¸ºdata URLåˆ—è¡¨
            images_list = [
                self._tensor_to_data_url(image1),
                self._tensor_to_data_url(image2),
            ]
            
            if image3 is not None:
                images_list.append(self._tensor_to_data_url(image3))
            
            # åˆ›å»ºArkå®¢æˆ·ç«¯
            client = Ark(
                base_url=api_base_url,
                api_key=effective_api_key,
            )
            
            print(f"ðŸŽ¨ æ­£åœ¨è°ƒç”¨Seedream APIæ‰¹é‡ç”Ÿæˆå›¾ç‰‡ (Multi-Image-to-Batch-Image)...")
            print(f"   æ¨¡åž‹: {model}")
            print(f"   è¾“å…¥å›¾ç‰‡æ•°: {len(images_list)}")
            print(f"   å°ºå¯¸: {size}")
            print(f"   æœ€å¤§å›¾ç‰‡æ•°: {max_images}")
            print(f"   æç¤ºè¯: {prompt[:100]}...")
            
            start_time = time.time()
            
            # è°ƒç”¨API - æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼
            images_response = client.images.generate(
                model=model,
                prompt=prompt,
                image=images_list,
                size=size,
                sequential_image_generation="auto",
                sequential_image_generation_options=SequentialImageGenerationOptions(max_images=max_images),
                response_format="url",
                watermark=watermark,
            )
            
            elapsed_time = time.time() - start_time
            
            # ä¸‹è½½æ‰€æœ‰å›¾ç‰‡
            if images_response.data and len(images_response.data) > 0:
                images = []
                for idx, image_data in enumerate(images_response.data):
                    image_url = image_data.url
                    image_size = getattr(image_data, 'size', 'unknown')
                    if image_url:
                        print(f"ðŸ“¥ ä¸‹è½½å›¾ç‰‡ {idx + 1}/{len(images_response.data)} (Size: {image_size})")
                        image_tensor = self._download_and_convert_image(image_url)
                        images.append(image_tensor)
                
                if images:
                    # åˆå¹¶æ‰€æœ‰å›¾ç‰‡ä¸ºbatch
                    batch_tensor = torch.cat(images, dim=0)
                    
                    status_message = (
                        f"âœ… å¤šå›¾ç”Ÿæ‰¹é‡å›¾ç‰‡æˆåŠŸï¼\n"
                        f"   ç”Ÿæˆå›¾ç‰‡æ•°: {len(images)}\n"
                        f"   æ¨¡åž‹: {model}\n"
                        f"   è€—æ—¶: {elapsed_time:.2f}ç§’"
                    )
                    print(status_message)
                    
                    return (batch_tensor, status_message)
            
            error_msg = f"âŒ æ— æ³•èŽ·å–å›¾ç‰‡"
            print(error_msg)
            empty_image = self._create_empty_image()
            return (empty_image, error_msg)
            
        except Exception as e:
            error_msg = f"âŒ å¤šå›¾ç”Ÿæ‰¹é‡å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            empty_image = self._create_empty_image()
            return (empty_image, error_msg)
    
    def _tensor_to_data_url(self, image_tensor: torch.Tensor) -> str:
        """å°†ComfyUIå›¾ç‰‡å¼ é‡è½¬æ¢ä¸ºdata URL"""
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor[0]
        
        image_np = (image_tensor.cpu().numpy() * 255).astype(np.uint8)
        image = Image.fromarray(image_np)
        
        buffer = BytesIO()
        image.save(buffer, format="PNG")
        b64_data = base64.b64encode(buffer.getvalue()).decode()
        
        return f"data:image/png;base64,{b64_data}"
    
    def _download_and_convert_image(self, url: str) -> torch.Tensor:
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼"""
        response = requests.get(url, timeout=60)
        response.raise_for_status()
        
        image = Image.open(BytesIO(response.content))
        image = image.convert("RGB")
        
        image_np = np.array(image).astype(np.float32) / 255.0
        image_tensor = torch.from_numpy(image_np)[None,]
        
        return image_tensor
    
    def _create_empty_image(self, width: int = 512, height: int = 512) -> torch.Tensor:
        """åˆ›å»ºç©ºç™½å›¾ç‰‡"""
        empty = np.zeros((height, width, 3), dtype=np.float32)
        return torch.from_numpy(empty)[None,]


class SeedreamMultiImageBlend:
    """
    BytePlus Seedream å¤šå›¾èžåˆèŠ‚ç‚¹
    ä½¿ç”¨å¤šå¼ å‚è€ƒå›¾ç‰‡èžåˆç”Ÿæˆå•å¼ æ–°å›¾ç‰‡ (éžæ‰¹é‡)
    """
    
    MODELS = SeedreamTextToImage.MODELS
    SIZES = SeedreamTextToImage.SIZES
    
    def __init__(self):
        pass
        
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image1": ("IMAGE", {
                    "tooltip": "ç¬¬ä¸€å¼ å‚è€ƒå›¾ç‰‡"
                }),
                "image2": ("IMAGE", {
                    "tooltip": "ç¬¬äºŒå¼ å‚è€ƒå›¾ç‰‡"
                }),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "Replace the clothing in image 1 with the outfit from image 2",
                    "tooltip": "èžåˆæŒ‡ä»¤"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": "",
                    "tooltip": "BytePlus APIå¯†é’¥"
                }),
                "model": (cls.MODELS, {
                    "default": "seedream-4-5-251128",
                    "tooltip": "é€‰æ‹©Seedreamæ¨¡åž‹ç‰ˆæœ¬"
                }),
                "size": (cls.SIZES, {
                    "default": "2K",
                    "tooltip": "ç”Ÿæˆå›¾ç‰‡çš„å°ºå¯¸"
                }),
            },
            "optional": {
                "image3": ("IMAGE", {
                    "tooltip": "ç¬¬ä¸‰å¼ å‚è€ƒå›¾ç‰‡ (å¯é€‰)"
                }),
                "api_base_url": ("STRING", {
                    "multiline": False,
                    "default": BYTEPLUS_API_BASE_URL,
                    "tooltip": "APIåŸºç¡€URL"
                }),
                "watermark": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("image", "image_url", "status_message")
    FUNCTION = "blend_images"
    CATEGORY = "image/generation"
    OUTPUT_NODE = True
    
    def blend_images(self, image1: torch.Tensor, image2: torch.Tensor, 
                     prompt: str, api_key: str, model: str, size: str,
                     image3: Optional[torch.Tensor] = None,
                     api_base_url: str = BYTEPLUS_API_BASE_URL,
                     watermark: bool = False):
        """
        è°ƒç”¨Seedream APIè¿›è¡Œå¤šå›¾èžåˆ (ä½¿ç”¨BytePlus Ark SDK)
        """
        try:
            # èŽ·å–APIå¯†é’¥
            effective_api_key = api_key if api_key else os.environ.get("ARK_API_KEY", "")
            if not effective_api_key:
                error_msg = "âŒ é”™è¯¯ï¼šæœªæä¾›APIå¯†é’¥"
                empty_image = self._create_empty_image()
                return (empty_image, "", error_msg)
            
            # å°†å›¾ç‰‡è½¬æ¢ä¸ºdata URLåˆ—è¡¨
            images_list = [
                self._tensor_to_data_url(image1),
                self._tensor_to_data_url(image2),
            ]
            
            if image3 is not None:
                images_list.append(self._tensor_to_data_url(image3))
            
            # åˆ›å»ºArkå®¢æˆ·ç«¯
            client = Ark(
                base_url=api_base_url,
                api_key=effective_api_key,
            )
            
            print(f"ðŸŽ¨ æ­£åœ¨è°ƒç”¨Seedream APIè¿›è¡Œå¤šå›¾èžåˆ...")
            print(f"   æ¨¡åž‹: {model}")
            print(f"   è¾“å…¥å›¾ç‰‡æ•°: {len(images_list)}")
            print(f"   æç¤ºè¯: {prompt[:100]}...")
            
            start_time = time.time()
            
            # è°ƒç”¨API (ä½¿ç”¨Ark SDK) - sequential_image_generation="disabled" è¡¨ç¤ºå•å›¾è¾“å‡º
            images_response = client.images.generate(
                model=model,
                prompt=prompt,
                image=images_list,
                size=size,
                sequential_image_generation="disabled",
                response_format="url",
                watermark=watermark,
            )
            
            elapsed_time = time.time() - start_time
            
            # èŽ·å–å›¾ç‰‡URL
            if images_response.data and len(images_response.data) > 0:
                image_url = images_response.data[0].url
                
                if image_url:
                    image_tensor = self._download_and_convert_image(image_url)
                    
                    status_message = (
                        f"âœ… å¤šå›¾èžåˆæˆåŠŸï¼\n"
                        f"   æ¨¡åž‹: {model}\n"
                        f"   è€—æ—¶: {elapsed_time:.2f}ç§’"
                    )
                    print(status_message)
                    
                    return (image_tensor, image_url, status_message)
            
            error_msg = f"âŒ æ— æ³•èŽ·å–å›¾ç‰‡URL"
            print(error_msg)
            empty_image = self._create_empty_image()
            return (empty_image, "", error_msg)
            
        except Exception as e:
            error_msg = f"âŒ å¤šå›¾èžåˆæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            empty_image = self._create_empty_image()
            return (empty_image, "", error_msg)
    
    def _tensor_to_data_url(self, image_tensor: torch.Tensor) -> str:
        """å°†ComfyUIå›¾ç‰‡å¼ é‡è½¬æ¢ä¸ºdata URL"""
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor[0]
        
        image_np = (image_tensor.cpu().numpy() * 255).astype(np.uint8)
        image = Image.fromarray(image_np)
        
        buffer = BytesIO()
        image.save(buffer, format="PNG")
        b64_data = base64.b64encode(buffer.getvalue()).decode()
        
        return f"data:image/png;base64,{b64_data}"
    
    def _download_and_convert_image(self, url: str) -> torch.Tensor:
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼"""
        response = requests.get(url, timeout=60)
        response.raise_for_status()
        
        image = Image.open(BytesIO(response.content))
        image = image.convert("RGB")
        
        image_np = np.array(image).astype(np.float32) / 255.0
        image_tensor = torch.from_numpy(image_np)[None,]
        
        return image_tensor
    
    def _create_empty_image(self, width: int = 512, height: int = 512) -> torch.Tensor:
        """åˆ›å»ºç©ºç™½å›¾ç‰‡"""
        empty = np.zeros((height, width, 3), dtype=np.float32)
        return torch.from_numpy(empty)[None,]


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "SeedreamTextToImage": SeedreamTextToImage,
    "SeedreamImageToImage": SeedreamImageToImage,
    "SeedreamTextToBatchImage": SeedreamTextToBatchImage,
    "SeedreamImageToBatchImage": SeedreamImageToBatchImage,
    "SeedreamMultiImageToBatchImage": SeedreamMultiImageToBatchImage,
    "SeedreamMultiImageBlend": SeedreamMultiImageBlend,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SeedreamTextToImage": "Seedream Text to Image (4.5)",
    "SeedreamImageToImage": "Seedream Image to Image (4.5)",
    "SeedreamTextToBatchImage": "Seedream Text to Batch Image (4.5)",
    "SeedreamImageToBatchImage": "Seedream Image to Batch Image (4.5)",
    "SeedreamMultiImageToBatchImage": "Seedream Multi-Image to Batch Image (4.5)",
    "SeedreamMultiImageBlend": "Seedream Multi-Image Blend (4.5)",
}
